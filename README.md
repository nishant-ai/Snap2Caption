# Snap2Caption

> *Turn any Instagram photo into a scrollâ€‘stopping post, complete with a tailored caption and trending hashtags, in under two seconds.*

---

## Meet **Aisha**, Our Customer  *(UnitÂ 1 â€“ Value Proposition)*

Aisha is a solo lifestyle creator who posts colourful city snapshots every evening after work.  She loves sharing, hates wordâ€‘smithing, and checks insights obsessively.  Snap2Caption exists for creators like her: upload a photo, get a punchy caption in her voice plus hashtags tuned to whatâ€™s hot **right now**.  To delight Aisha we committed to:

* **Zero friction**Â â†’ a single `/generate-caption` call that runs anywhere she can curl.
* **Timely trend awareness**Â â†’ overnight reâ€‘training so the hashtag list mirrors todayâ€™s conversations.
* **Mobileâ€‘first speed**Â â†’ P90 latency <â€¯2â€¯s so she can post while her coffee is still hot.

Those promises ripple through every design choice that follows.

---

## From Pixels to Parquet â€”â€¯**Data Foundations**  *(UnitÂ 8)*

Our journey starts with **InstaCities1M** (â‰ˆâ€¯50â€¯GB).  A nightly ETL job â€“ [`pipelines/data_ingest.py`](./pipelines/data_ingest.py) â€“ fetches fresh URLs, validates JPEGs, and writes them to an S3â€‘compatible bucket provisioned in [`infra/terraform/storage.tf`](./infra/terraform/storage.tf).  A companion script, [`pipelines/preprocess.py`](./pipelines/preprocess.py), resizes each image to `300Ã—300`, wraps it in our chat template, and records the result in Parquet.

```mermaid
flowchart LR
A[InstaCities URLs] -->|download| B(s3://snap2caption-raw)
B --> C[Preâ€‘process & check]
C --> D[Parquet manifest]
D --> E{Split 80/10/10}
E --> F[train] & G[val] & H[prod]
```

Persistent volumes:

| Mount                          | Purpose                   | Size  | Kind            |
| ------------------------------ | ------------------------- | ----- | --------------- |
| `/mnt/object/snap2caption-raw` | Raw & processed images    | 50â€¯GB | Object store    |
| `/mnt/block/checkpoints`       | Model & tokenizer weights | 25â€¯GB | Rookâ€‘Ceph block |
| `/mnt/block/experiments`       | WeightsÂ &Â Biases cache    | 10â€¯GB | Block           |

Online, every inference request and user rating flows through [`schemas/online_event.avsc`](./schemas/online_event.avsc) into Kafka, lands in `/mnt/block/online_events`, and is swept nightly by [`pipelines/online_consumer.py`](./pipelines/online_consumer.py).  A Spark job joins these logs with engagement metrics, computes KLâ€‘drift; when drift >â€¯0.15, Prometheus fires an alert that kicks off reâ€‘training.

---

## Teaching the Model â€”â€¯**Training & Experimentation**  *(UnitsÂ 4â€¯&â€¯5)*

Captions are natural language; hashtags are ranked keyword strings.  We frame this as *imageâ€‘conditioned sequence generation* and fineâ€‘tune **LLaVAâ€‘1.5â€‘7B** with rankâ€‘16 LoRA adapters.

* Training entryâ€‘point: [`src/train/train.py`](./src/train/train.py)
* Distributed engine (DDPÂ + FP16): [`src/train/engine.py`](./src/train/engine.py)
* Weekly scheduled job: [`k8s/cron_retrain.yaml`](./k8s/cron_retrain.yaml)

> **Result:**  DDP slashed wallâ€‘clock from 8â€¯h to **5â€¯h** on 4Ã—Â A100â€‘80G while BLEUâ€‘4 climbed to **0.31**.

Experiments are logged to MLflow (run `make mlflow-ui`), artefacts live under [`mlruns/`](./mlruns).

---

## Shipping Intelligence â€”â€¯**Infrastructure & Continuous Delivery**  *(UnitsÂ 2Â &Â 3)*

Aisha need never see our plumbing, but reliability starts here.

<img src="docs/architecture.svg" alt="architecture diagram" width="720"/>

Everything is code:

| Layer                                        | Repo Path                                                      |
| -------------------------------------------- | -------------------------------------------------------------- |
| Terraform modules                            | [`infra/terraform`](./infra/terraform)                         |
| Helm chart                                   | [`infra/helm`](./infra/helm)                                   |
| Raw k8s resources (CronJobs, HPAs, Rollouts) | [`k8s/`](./k8s)                                                |
| ArgoÂ CD bootstrap                            | [`infra/argocd_bootstrap.yaml`](./infra/argocd_bootstrap.yaml) |

GitHub Actions workflow [`.github/workflows/pipeline.yaml`](./.github/workflows/pipeline.yaml) builds and pushes every commit, then ArgoÂ CD syncs **staging**.  Promotion to **canary** and finally **prod** is governed by ArgoÂ Rollouts (`k8s/rollout.yaml`).  The same pipeline restarts when a drift alert creates a GitHubÂ Release, ensuring model, serving image, and manifests march forward together.

Deploying on **Chameleon Cloud** is a threeâ€‘step tale:

```bash
# 1. spin up GPU k8s and storage
make chi-init && make chi-apply

# 2. bootstrap Argo CD & let it deploy the chart
make argocd-bootstrap

# 3. watch the rollout, then fire a test call
make argocd-watch &
python demo_request.py sample.jpg
```

---

## Serving the Magic â€”â€¯**Realâ€‘time Inference & Evaluation**  *(UnitsÂ 6Â &Â 7)*

The FastAPI server in [`src/serve/app.py`](./src/serve/app.py) loads an ONNXâ€‘exported, 8â€‘bitâ€‘quantised checkpoint (`scripts/convert_to_onnx.py`).  Images stream through a turboâ€‘JPEG decoder (`src/serve/decoder.py`) before tokenisation.  KEDA watches request count and scales the deployment (`k8s/keda_scaledobject.yaml`) from 0 to 10 replicas.

```text
POST /generate-caption
{ "image_base64": "â€¦" }
â†’ { "caption": "Golden hour coffee vibes â˜•ðŸŒ‡", "hashtags": ["#citysunset", â€¦] }
```

Quality & reliability are gateâ€‘checked by:

* **Offline tests** â€“ [`tests/offline`](./tests/offline): run `pytest -q`
* **Load tests** â€“ [`tests/load/locustfile.py`](./tests/load/locustfile.py): run `make load-test`
* **Dashboards & alerts** â€“ Grafana JSON in [`docs/grafana`](./docs/grafana); alert rules in [`k8s/alerts.yaml`](./k8s/alerts.yaml)

Aishaâ€™s optional thumbsâ€‘up/down hits [`src/serve/feedback.py`](./src/serve/feedback.py); the rating joins the online log, nudging the next training set toward what *she* likes.

---

## Repository Atlas

| Folder       | What youâ€™ll find                         |
| ------------ | ---------------------------------------- |
| `infra/`     | Terraform, Helm, Argocd bootstrap        |
| `k8s/`       | CronJobs, HPAs, Rollouts, alerting       |
| `pipelines/` | Data ingest, preprocess, online consumer |
| `src/train/` | Training & experimentation code          |
| `src/serve/` | Inference service & helpers              |
| `tests/`     | Offline unit + load tests                |
| `docs/`      | Diagrams, Grafana dashboards             |

---

## Local Taste Test

```bash
make docker-build
make docker-run
python demo_request.py sample.jpg
```

---

## License

MIT
