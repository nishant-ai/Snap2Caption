# --- Experiment Metadata ---
run_name: "snap2caption-instagram-v1.6-mistral"
project: "ImageCaptioning"
model_name: "LLaVA-1.6-Mistral-LoRA"
task: "captioning"
notes: "Fine-tuning LLaVA-NeXT (v1.6) with LoRA adapters on InstaCities1M"
description: "Captions for Instagram-like images with optional eval/test phases using llava-hf/llava-v1.6-mistral-7b-hf."

# --- Dataset Configuration ---
dataset:
  name: "InstaCities1M"
  cities: ["new york", "san francisco", "chicago"]

  # Dataset locations (adjusted for Docker mount)
  train_base_dir: "/mnt/dataset/Training/cities_instagram"
  eval_base_dir: "/mnt/dataset/Evaluation/cities_instagram"
  test_base_dir: "/mnt/dataset/Testing/cities_instagram"
  output_jsonl_path: "./compiled.jsonl"

  # Controls which sampling logic to apply
  split_mode: "count"  # "percent" or "count"

  # If split_mode == "percent"
  train_split: 0.7
  eval_split: 0.2
  test_split: 0.1

  # If split_mode == "count"
  train_count: 1500
  eval_count: 1500
  test_count: 1500

# --- LoRA Configuration ---
lora:
  r: 16
  alpha: 32
  dropout: 0.05
  target_modules: ["q_proj", "v_proj"]

# --- Model Configuration ---
model:
  id: "llava-hf/llava-v1.6-mistral-7b-hf"
  save_path: "./outputs/llava_lora_instagram"

# --- Training Configuration ---
training:
  batch_size: 2
  grad_accum_steps: 4
  epochs: 1
  learning_rate: 5e-5
  logging_steps: 10
  weight_decay: 0.01

# --- MLflow and Logging ---
mlflow_ip: "http://129.114.25.254:8000"
bypass_save: false

# --- Prompt Template ---
llava_prompt: >
  You are a social media influencer. Write a captivating Instagram caption for this image
  that will engage more viewers and boost interaction. Analyze the image to decide the tone of the caption.